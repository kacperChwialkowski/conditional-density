% LaTeX file for a 1 page document
\documentclass[10pt]{article}
\usepackage{amssymb,amsmath}
\usepackage{amsthm}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{Theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{statement}{Statement}
\newtheorem{corollary}{Corollary}
\newtheorem{test}{Test}
\newtheorem{proposition}{Proposition}


\title{Conditional density estimation}


\begin{document}
\maketitle

\begin{abstract}
\end{abstract}




\section{One approach}
\label{sec:option1}
Here we will assume that the conditional density can be written as 
\begin{equation}
p_0(x|y) = q(x,y)exp(f(x,y) - A(T))
\end{equation} 
By Proposition 1 from the paper [Inf] quite a few conditional densities can be approximated by functions of this type. We need to redefine Fisher divergence   
\begin{align}
J(p_0|p) &= \int \left( \int p_0(x|y) \parallel \frac{\partial  f_0(x,y)} {\partial x} -\frac{\partial  f(x,y)} {\partial x} \parallel^2 \right )p(y) dx dy  \\
&=  \int  \parallel \frac{\partial  f_0(x,y)} {\partial x} -\frac{\partial  f(x,y)} {\partial x} \parallel^2 p_0(x,y) dx dy \\
&=  \int   \left \langle f-f_0,\frac{\partial  k( (x,y), \cdot)} {\partial x} \right \rangle^2    p_0(x,y) dx dy
\end{align}
The reasoning for the Theorem 3 follows. For the sake of simplicity I assume that $x$ is one dimensional. In particular we have that 
\begin{equation}
 C := \int  p_0(x,y) \frac{\partial  k( (x,y), \cdot)} {\partial x} \otimes \frac{\partial  k( (x,y), \cdot)} {\partial x} dx dy
\end{equation}
and 
\begin{equation}
 J(f) := J(p_0|p) = \langle (f -f_0),C(f -f_0) \rangle.
\end{equation}
Also 
\begin{equation}
 J(f) = \langle f,Cf \rangle + \langle f,\xi \rangle + Const
\end{equation}
but $\xi$ is looks sightly different. Using the fact that
\begin{equation}
 \frac{\partial  f(x,y)} {\partial x}  = \frac{\partial  \log p_0(x|y)}{\partial x} - \frac{\partial  \log q(x,y)}{\partial x}
\end{equation}

\begin{align}
&\langle f,Cf_0 \rangle \\
=& \int p_0(x,y) \frac{\partial  f(x,y)} {\partial x} \frac{\partial  f_0(x,y)} {\partial x} dx dy \\
=& \int p_0(x,y) \frac{\partial  f(x,y)} {\partial x} \frac{\partial  \log p_0(x|y)}{\partial x} - \int p_0(x,y) \frac{\partial  f(x,y)} {\partial x} \frac{\partial  \log q(x,y)}{\partial x} \\
=&  \int   \left(\int  \frac{\partial  f(x,y)} {\partial x} \frac{\partial  p_0(x|y)}{\partial x} dx \right) p(y) dy 
- \int p_0(x,y) \frac{\partial  f(x,y)} {\partial x} \frac{\partial  \log q(x,y)}{\partial x} dx dy \\
\end{align}
Now the first inner  integral (check that it exists !) will be reduced by integration by parts  
\begin{align}
\int&  \frac{\partial  f(x,y)} {\partial x} \frac{\partial  p_0(x|y)}{\partial x} dx \\
&=  \frac{\partial f(x,y)} {\partial x} p_0(x|y) \mid_{-\infty}^{\infty} - \int \frac{\partial f(x,y)} {\partial x}^2 p_0(x|y)
\end{align}
we assume that $\frac{\partial f(x,y)} {\partial x} p_0(x|y) \mid_{-\infty}^{\infty} =0$, plug in and have 
\begin{align}
&\langle f,Cf_0 \rangle \\
=&  \int   \frac{\partial f(x,y)} {\partial x}^2  p_0(x,y) dx dy - \int p_0(x,y) \frac{\partial  f(x,y)} {\partial x} \frac{\partial  \log q(x,y)}{\partial x} dx dy \\
=& -\int p_0(x,y) \left \langle f , \frac{\partial  k( (x,y), \cdot)} {\partial x}^2+ \frac{\partial  k( (x,y), \cdot)} {\partial x}\frac{\partial  \log q(x,y)}{\partial x} \right \rangle
\end{align}
so 
\begin{equation}
 \xi =-\int p_0(x,y)  \left( \frac{\partial  k( (x,y), \cdot)} {\partial x}^2+ \frac{\partial  k( (x,y), \cdot)} {\partial x}\frac{\partial  \log q(x,y)}{\partial x} \right)
\end{equation}
We don't really care about the third since it is constant.


\section{Other option}
\label{sec:option2}
Consider a function $T(x,y)$ which is a bilinear form in some Hilbert space  $T(x,y) = \langle \phi(x), T \phi(y) \rangle $, where mapping $\phi$ and is an injection to some RKHS. Consider the following function
\begin{equation}
p(x|y) = q(x,y)exp(T(x,y) - A(T)),
\end{equation}
such that for all 
\begin{equation}
\label{eq:toOne}
 \int q(x,y)exp(T(x,y) - A(T)) = 1. 
\end{equation}
We consider Fisher divergence of $p(x|y)$ and the true conditional density $p(x|y)_0$, we suppose that $g_0$ is a true density associated with $f_0$ 
\begin{equation}
J(f_0|f) = \int g_0(x,y) \parallel \frac{\partial T(x,y)} {\partial x} -\frac{\partial T(x,y)} {\partial x} \parallel^2 dx dy  
\end{equation}

\section{Yet another solution}
The problem with solution \ref{sec:option1} and \ref{sec:option2} is that we can not enforce that 
\begin{equation}
 \int p(x|y) dx = 1,
\end{equation}
and therefore we have to re-normalize the functions that we get. One way to solve it would be use different form of a density e.g.
\begin{equation}
 p(x|y) = f(x,y)^2
\end{equation}
and different divergence i.e.
\begin{equation}
 J(f_0|f) = \int \int (f(x,y)^2 - f_0(x,y)^2)^2 p_0(y) dx dy 
\end{equation}
now we can actually enforce that 
\begin{equation}
\int f(x,y)^2 =1,  
\end{equation}
since it is possible to show that the solution will be of the  form $\sum_{i=1}^n \alpha_i k((x_i,y_i),(x,y))$ and $x$ can be (sometimes) analytically integrated out so that we have an equality  constraint on the minimization problem. But we need to show that the solution will be of this form.


\begin{align}
 J(f_0|f) &= \int f^4(x,y) p_0(y) dx dy - 2 \int f^2(x,y) f_0^2(x,y) p(y) dx dy + \int f^4(x,y) p_0(y) dx dy 
\end{align}
For the first term there exists a tensor $C_4 = \int \phi(x,y) \otimes \phi(x,y) \otimes \phi(x,y) \otimes \phi(x,y) p_0(y) dx dy$, such that 
\begin{equation}
 \int f(x,y)^4 p_0(y) dx dy = \langle f \otimes f \otimes f \otimes f , C_4 \rangle.
\end{equation}
For the middle term 
\begin{align}
\int &f^2(x,y) f_0^2(x,y) p(y) dx dy = \int f^2(x,y) p_0(x,y) \\
 =&  \langle f \otimes f  , \int \phi(x,y) \otimes \phi(x,y) p_0(x,y) \rangle \\
 =& \langle f \otimes f  , C_2 \rangle.
\end{align}
Last term is constant. The empirical tensors $C_2$ and $C_4$ are quite different. We assume that $\phi(x,y) = \phi(x) \otimes \phi(y)$ (implicit indexes $ \phi_x(x)$ etc.) The first one is 
\begin{equation}
 C_4 = \left( \int \phi(x) \otimes \phi(x) \otimes \phi(x) \otimes \phi(x) dx  \right)  \otimes \left( \frac 1 n\sum_{1 \leq i \leq n}  \phi(Y_{i}) \otimes \phi(Y_{i}) \otimes \phi(Y_{i}) \otimes \phi(Y_{i}) \right). 
\end{equation}
$C_2$ is
\begin{equation}
 C_2 = \frac 1 n \sum_{1 \leq i \leq n } \phi(Y_{i},X_{i}) \otimes \phi(Y_{i},X_{i}) 
\end{equation}
The empirical divergence looks much nicer
\begin{align}
 \langle f, \phi(x) \otimes
\end{align}
We need to notice that none of the terms in $C_4$ imply any restrictions on the solution i.e. for any $f$  
\begin{equation}
 \langle  (\otimes f)^4  ,  \left( \int  (\otimes \phi(x))^4 dx  \right)  \otimes \left(    (\otimes \phi(Y_{i}))^4 \right) \rangle = \int f(x,y_i)^4 dx > 0
\end{equation}
i.e. $C_2$ has no null space. On the other hand $\bar C_2$ imposes some conditions about solution, since 
\begin{equation}
 \langle f, \bar C_2 f \rangle = \frac 1 n \sum_{i=1}^n \langle f , \phi(X_i,Y_i) \rangle^2   
\end{equation}
so the solution should be spanned by the $H = \{ \phi(X_i,Y_i) \}_{1 \leq i \leq n}$. Suppose that divergence is minimized by some $h = h_1 + h_2$ where $h_1 \in H$ and $h_2$ sits in the orthonormal complement of $H$. Then 
\begin{equation}
 \langle h_1 + h_2 , \phi(X_i,Y_i) \rangle^2 =\langle h_1 , \phi(X_i,Y_i) \rangle
\end{equation}
so the second term is not getting smaller. Adding $h_2$ to the solution might minimize the first term, but it is unclear what should be added. We will show that as we increase the number of the observations we are getting closer to a function $h_1 + h_2$ that minimizes the whole expression.
For now we calculate the empirical divergence. The second part is
\begin{align}
  \langle f, \bar C_2 f \rangle = \frac 1 n \sum_{i=1}^n \langle f , \phi(X_i,Y_i) \rangle^2 \\
  = \frac 1 n \sum_{i=1}^n \langle \sum_{j=1}^{n} \alpha_j \phi(X_j,Y_j) , \phi(X_i,Y_i) \rangle^2 \\
   = \frac 1 n \sum_{i,j_1,j_2=1}^n \alpha_{j_1} \alpha_{j_2} k(X_{j_1},X_i) k(X_{j_2},X_i)  k(Y_{j_1},Y_i) k(Y_{j_2},Y_i) 
\end{align}
And the first term looks like that 
\begin{align}
  \frac 1 n \sum_{i=1}^n \langle  (\otimes f)^4  ,  \left( \int  (\otimes \phi(x))^4 dx  \right)  \otimes \left(    (\otimes \phi(Y_{i}))^4 \right) \rangle \\
  = \frac 1 n \sum_{i=1}^n \langle  ( \sum_{j=1}^{n} \alpha_j \phi(X_j,Y_j))^4  ,  \left( \int  (\otimes \phi(x))^4 dx  \right)  \otimes \left(    (\otimes \phi(Y_{i}))^4 \right) \rangle \\
  =\frac 1 n \sum_{i,j_1,j_2,j_3,j_4=1}^n  \alpha_{j_1} \alpha_{j_2} \alpha_{j_3} \alpha_{j_4} \langle \phi(X_{j_1}) \otimes (Y_{j_1}) \otimes  \phi(X_{j_2}) \otimes (Y_{j_2}) \otimes  \phi(X_{j_3}) \otimes (Y_{j_3}) \otimes  \phi(X_{j_4}) \otimes (Y_{j_4})\\
  ,\left( \int  (\otimes \phi(x))^4 dx  \right)  \otimes \left(    \otimes \phi(Y_{i}) \right)^4 \rangle \\
  =\frac 1 n \sum_{i,j_1,j_2,j_3,j_4=1}^n  \alpha_{j_1} \alpha_{j_2} \alpha_{j_3} \alpha_{j_4} \left( \int k(X_{j_1},x) k(X_{j_2},x) k(X_{j_3},x) k(X_{j_4},x)  dx \right) \\ 
    k(Y_{j_1},Y_i) k(Y_{j_2},Y_i)k(Y_{j_3},Y_i)k(Y_{j_4},Y_i)
\end{align}
This integral is a sad little thing, but basically there are two cases. Either after integration we can factorize the result or not. If we can (we can for Gaussian kernel ) we have  
\begin{align}
 =\frac 1 n \sum_{i,j_1,j_2,j_3,j_4=1}^n  \alpha_{j_1} \alpha_{j_2} \alpha_{j_3} \alpha_{j_4}  f(X_{j_1}) f(X_{j_2}) f(X_{j_3}) f(X_{j_4})   \\ 
    k(Y_{j_1},Y_i) k(Y_{j_2},Y_i)k(Y_{j_3},Y_i)k(Y_{j_4},Y_i)
\end{align}
Finally we need to calculate the constraint
\begin{align}
 \int \left( \sum_{j=1}^{n} \alpha_j  k(X_{j},x)  k(Y_{j},y) \right )^2 dx \\ 
 = \int  \sum_{j,i=1}^{n} \alpha_j  k(X_{j},x)  k(Y_{j},y) k(X_{i},x)  k(Y_{i},y)  dx\\
 =   \sum_{j,i=1}^{n} \alpha_j  f(X_{j},x)  k(Y_{j},y) f(X_{i},x)  k(Y_{i},y)  \\
\end{align}
The latter must be equal to to.

Now we need to prove that we recover optimal solution asymptotically. We know that $f$ can be written as $f = \sum_{i=1}^{D} \phi(X_i,Y_i)$. Set $D$ trap-balls of radius $\epsilon/D$ around those $D$ points and wait until all traps are non-empty. Using Borel-Cantelli we know that we will succeed since the probability of falling into any of the traps is positive.          








\end{document}
